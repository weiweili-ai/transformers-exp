# transformers-exp
## introduction
- Transformers 库的主要概念
- Transformer 模型的工作原理 
- 如何使用 Hugging Face Hub 中的模型
- 如何在数据集上对其进行微调
- 如何在 Hub 上分享你的结果

## diving in
**Datasets** 和 **Tokenizers** 的基础知识

## advanced
超越 NLP，探讨如何使用 Transformer 模型解决语音处理和计算机视觉任务。
在此过程中，将学习如何构建和分享模型的演示，并将它们优化为生产环境。
完成这部分课程后，你将准备好将 **Transformers** 应用于（几乎）任何机器学习问题！

##Transformer 模型大体上可以分为三类：

GPT-like （也被称作自回归 Transformer 模型）
BERT-like （也被称作自动编码 Transformer 模型）
BART/T5-like （也被称作序列到序列的 Transformer 模型）

[DistilBert](image.png)
